{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Vizualisation (Matplotlib, Plotly, Seaborn, etc. )\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EDA (pandas-profiling, etc. )\n",
    "...\n",
    "\n",
    "# Feature Processing (Scikit-learn processing, etc. )\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "\n",
    "# Machine Learning (Scikit-learn Estimators, Catboost, LightGBM, etc. )\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report#, accuracy\n",
    "\n",
    "# Hyperparameters Fine-tuning (Scikit-learn hp search, cross-validation, etc. )\n",
    "...\n",
    "\n",
    "# Other packages\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school = pd.read_csv('../dataset/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['Target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['Target'] = np.where(df_school['Target'] == 'Dropout', 'YES', 'NO')\n",
    "# Convert 'Dropout_Flag' to numeric values: 1 for 'YES', 0 for 'NO'\n",
    "df_school['Target'] = df_school['Target'].apply(lambda x: 1 if x == 'YES' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['Target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = df_school['Target'].value_counts()\n",
    "\n",
    "# Create a bar plot for visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1], labels=['NO', 'YES'])  # Ensure that x-ticks correspond to 'NO' and 'YES'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "column_mapping = {\n",
    "    'Marital status': 'MaritalStat',\n",
    "    'Application mode': 'AppMode',\n",
    "    'Application order': 'AppOrder',\n",
    "    'Course': 'Course',\n",
    "    'Daytime/evening attendance': 'DayEveningAtt',\n",
    "    'Previous qualification': 'PrevQual',\n",
    "    'Nacionality': 'Nationality',  \n",
    "    \"Mother's qualification\": 'MotherQual',\n",
    "    \"Father's qualification\": 'FatherQual',\n",
    "    \"Mother's occupation\": 'MotherOcc',\n",
    "    \"Father's occupation\": 'FatherOcc',\n",
    "    'Displaced': 'Displaced',\n",
    "    'Educational special needs': 'EduNeeds',\n",
    "    'Debtor': 'Debtor',\n",
    "    'Tuition fees up to date': 'FeesUpdated',\n",
    "    'Gender': 'Gender',\n",
    "    'Scholarship holder': 'Scholarship',\n",
    "    'Age at enrollment': 'AgeEnroll',\n",
    "    'International': 'International',\n",
    "    'Curricular units 1st sem (credited)': 'CU1Credited',\n",
    "    'Curricular units 1st sem (enrolled)': 'CU1Enrolled',\n",
    "    'Curricular units 1st sem (evaluations)': 'CU1Evaluations',\n",
    "    'Curricular units 1st sem (approved)': 'CU1Approved',\n",
    "    'Curricular units 1st sem (grade)': 'CU1Grade',\n",
    "    'Curricular units 1st sem (without evaluations)': 'CU1NoEvals',\n",
    "    'Curricular units 2nd sem (credited)': 'CU2Credited',\n",
    "    'Curricular units 2nd sem (enrolled)': 'CU2Enrolled',\n",
    "    'Curricular units 2nd sem (evaluations)': 'CU2Evaluations',\n",
    "    'Curricular units 2nd sem (approved)': 'CU2Approved',\n",
    "    'Curricular units 2nd sem (grade)': 'CU2Grade',\n",
    "    'Curricular units 2nd sem (without evaluations)': 'CU2NoEvals',\n",
    "    'Unemployment rate': 'UnempRate',\n",
    "    'Inflation rate': 'InflationRate',\n",
    "    'GDP': 'GDP',\n",
    "    'Target': 'Target'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_school.rename(columns=column_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender replacement\n",
    "gender_replace = {\n",
    "    1: 'male',\n",
    "    0: 'female'\n",
    "}\n",
    "df_school['Gender'] = df_school['Gender'].replace(gender_replace)\n",
    "\n",
    "# Nationality replacement\n",
    "nationality_replace = {\n",
    "    1: 'Portuguese', 2: 'German', 3: 'Spanish', 4: 'Italian', 5: 'Dutch', 6: 'English',\n",
    "    7: 'Lithuanian', 8: 'Angolan', 9: 'Cape Verdean', 10: 'Guinean', 11: 'Mozambican',\n",
    "    12: 'Santomean', 13: 'Turkish', 14: 'Brazilian', 15: 'Romanian', 16: 'Moldova (Republic of)',\n",
    "    17: 'Mexican', 18: 'Ukrainian', 19: 'Russian', 20: 'Cuban', 21: 'Colombian'\n",
    "}\n",
    "df_school['Nationality'] = df_school['Nationality'].replace(nationality_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values in 'Marital status'\n",
    "marital_mapping = {\n",
    "    1: 'Single',\n",
    "    2: 'Married',\n",
    "    3: 'Widower',\n",
    "    4: 'Divorced',\n",
    "    5: 'Facto union',\n",
    "    6: 'Legally separated'\n",
    "}\n",
    "\n",
    "df_school['MaritalStat'] = df_school['MaritalStat'].replace(marital_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualification_mapping = {\n",
    "    1: 'Secondary Education',\n",
    "    2: 'Higher Education - Undergraduate',\n",
    "    3: 'Higher Education - Undergraduate',\n",
    "    4: 'Higher Education - Graduate',\n",
    "    5: 'Higher Education - Graduate',\n",
    "    6: 'Higher Education - Undergraduate',\n",
    "    7: 'Primary Education',\n",
    "    8: 'Primary Education',\n",
    "    9: 'Primary Education',\n",
    "    10: 'Secondary Education',\n",
    "    11: 'Secondary Education',\n",
    "    12: 'Secondary Education',\n",
    "    13: 'Secondary Education',\n",
    "    14: 'Secondary Education',\n",
    "    15: 'Secondary Education',\n",
    "    16: 'Vocational/Technical',\n",
    "    17: 'Secondary Education',\n",
    "    18: 'Primary Education',\n",
    "    19: 'Secondary Education',\n",
    "    20: 'Primary Education',\n",
    "    21: 'Primary Education',\n",
    "    22: 'Secondary Education',\n",
    "    23: 'Secondary Education',\n",
    "    24: 'Unknown',\n",
    "    25: 'Primary Education',\n",
    "    26: 'Primary Education',\n",
    "    27: 'Primary Education',\n",
    "    28: 'Primary Education',\n",
    "    29: 'Vocational/Technical',\n",
    "    30: 'Higher Education - Undergraduate',\n",
    "    31: 'Higher Education - Undergraduate',\n",
    "    32: 'Higher Education - Undergraduate',\n",
    "    33: 'Higher Education - Graduate',\n",
    "    34: 'Higher Education - Graduate'\n",
    "}\n",
    "\n",
    "# Grouping the qualification categories\n",
    "grouped_qualifications = {\n",
    "    'Primary Education': 'Primary Education',\n",
    "    'Secondary Education': 'Secondary Education',\n",
    "    'Higher Education - Undergraduate': 'Higher Education',\n",
    "    'Higher Education - Graduate': 'Higher Education',\n",
    "    'Vocational/Technical': 'Vocational/Technical',\n",
    "    'Unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "\n",
    "df_school[\"FatherQual\"] = df_school[\"FatherQual\"].map(qualification_mapping)\n",
    "df_school[\"FatherQual\"] = df_school[\"FatherQual\"].replace(grouped_qualifications)\n",
    "\n",
    "df_school[\"MotherQual\"] = df_school[\"MotherQual\"].map(qualification_mapping)\n",
    "df_school[\"MotherQual\"] = df_school[\"MotherQual\"].replace(grouped_qualifications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping courses\n",
    "course_mapping = {\n",
    "    1: 'Biofuel Production Technologies',\n",
    "    2: 'Animation and Multimedia Design',\n",
    "    3: 'Social Service (evening attendance)',\n",
    "    4: 'Agronomy',\n",
    "    5: 'Communication Design',\n",
    "    6: 'Veterinary Nursing',\n",
    "    7: 'Informatics Engineering',\n",
    "    8: 'Equiniculture',\n",
    "    9: 'Management',\n",
    "    10: 'Social Service',\n",
    "    11: 'Tourism',\n",
    "    12: 'Nursing',\n",
    "    13: 'Oral Hygiene',\n",
    "    14: 'Advertising and Marketing Management',\n",
    "    15: 'Journalism and Communication',\n",
    "    16: 'Basic Education',\n",
    "    17: 'Management (evening attendance)'\n",
    "}\n",
    "\n",
    "# Define a new mapping from course names to broader categories\n",
    "new_course_mapping = {\n",
    "    'Biofuel Production Technologies': 'Science and Technology',\n",
    "    'Animation and Multimedia Design': 'Arts, Design, and Social Sciences',\n",
    "    'Social Service (evening attendance)': 'Arts, Design, and Social Sciences',\n",
    "    'Agronomy': 'Science and Technology',\n",
    "    'Communication Design': 'Arts, Design, and Social Sciences',\n",
    "    'Veterinary Nursing': 'Health, Business, and Management',\n",
    "    'Informatics Engineering': 'Science and Technology',\n",
    "    'Equiniculture': 'Arts, Design, and Social Sciences',\n",
    "    'Management': 'Health, Business, and Management',\n",
    "    'Social Service': 'Arts, Design, and Social Sciences',\n",
    "    'Tourism': 'Arts, Design, and Social Sciences',\n",
    "    'Nursing': 'Health, Business, and Management',\n",
    "    'Oral Hygiene': 'Health, Business, and Management',\n",
    "    'Advertising and Marketing Management': 'Health, Business, and Management',\n",
    "    'Journalism and Communication': 'Arts, Design, and Social Sciences',\n",
    "    'Basic Education': 'Arts, Design, and Social Sciences',\n",
    "    'Management (evening attendance)': 'Health, Business, and Management'\n",
    "}\n",
    "\n",
    "# First map the course IDs to names, then map names to broader categories\n",
    "df_school['Course'] = df_school['Course'].map(course_mapping)\n",
    "df_school['Course'] = df_school['Course'].map(new_course_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping 'Daytime/evening attendance' column\n",
    "df_school['DayEveningAtt'] = df_school['DayEveningAtt'].replace({1: 'daytime', 0: 'evening'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['PrevQual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_qual_mapping = {\n",
    "    1: 'Secondary Education',\n",
    "    12: 'Basic Education',\n",
    "    16: 'Higher Education (Undergraduate)',\n",
    "    14: 'Other or Vocational Training',\n",
    "    8: 'Incomplete Secondary Education',\n",
    "    3: 'Higher Education (Undergraduate)',\n",
    "    15: 'Higher Education (Undergraduate)',\n",
    "    2: 'Higher Education (Undergraduate)',\n",
    "    4: 'Higher Education (Postgraduate)',\n",
    "    9: 'Other or Vocational Training',\n",
    "    17: 'Higher Education (Postgraduate)',\n",
    "    11: 'Basic Education',\n",
    "    6: 'Other or Vocational Training',\n",
    "    7: 'Incomplete Secondary Education',\n",
    "    13: 'Basic Education',\n",
    "    5: 'Higher Education (Postgraduate)',\n",
    "    10: 'Basic Education'\n",
    "}\n",
    "\n",
    "df_school['PrevQual'] = df_school['PrevQual'].map(prev_qual_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['Scholarship'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 0 to 'No' and 1 to 'Yes'\n",
    "scholarship_mapping = {0: 'No', 1: 'Yes'}\n",
    "\n",
    "# Apply the mapping to the 'Scholarship' column\n",
    "df_school['Scholarship'] = df_school['Scholarship'].map(scholarship_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['AppMode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_mode_mapping = {\n",
    "    1: 'General Admission', 8: 'General Admission', 9: 'General Admission', 12: 'General Admission',\n",
    "    2: 'Special Contingents or Conditions', 3: 'Special Contingents or Conditions', 4: 'Special Contingents or Conditions', \n",
    "    5: 'Special Contingents or Conditions', 6: 'Special Contingents or Conditions', 7: 'Special Contingents or Conditions', \n",
    "    10: 'Special Contingents or Conditions', 11: 'Special Contingents or Conditions',\n",
    "    13: 'Course/Institution Changes', 14: 'Course/Institution Changes', 15: 'Course/Institution Changes', \n",
    "    16: 'Course/Institution Changes', 17: 'Course/Institution Changes', 18: 'Course/Institution Changes'\n",
    "}\n",
    "\n",
    "df_school['AppMode'] = df_school['AppMode'].map(app_mode_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['AppOrder'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['MotherOcc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_mapping = {\n",
    "    # Mapping for Highly Skilled or Professional Occupations\n",
    "    1: 'Highly Skilled/Professional', 2: 'Highly Skilled/Professional', 3: 'Highly Skilled/Professional', \n",
    "    4: 'Highly Skilled/Professional', 5: 'Highly Skilled/Professional', 16: 'Highly Skilled/Professional', \n",
    "    20: 'Highly Skilled/Professional', 21: 'Highly Skilled/Professional', 19: 'Highly Skilled/Professional', \n",
    "    23: 'Highly Skilled/Professional', 24: 'Highly Skilled/Professional', 25: 'Highly Skilled/Professional', \n",
    "    26: 'Highly Skilled/Professional', 22: 'Highly Skilled/Professional', 17: 'Highly Skilled/Professional', \n",
    "    18: 'Highly Skilled/Professional', 29: 'Highly Skilled/Professional', 28: 'Highly Skilled/Professional', \n",
    "    27: 'Highly Skilled/Professional',\n",
    "\n",
    "    # Mapping for Skilled or Semi-Skilled Occupations\n",
    "    6: 'Skilled/Semi-Skilled', 7: 'Skilled/Semi-Skilled', 8: 'Skilled/Semi-Skilled', \n",
    "    9: 'Skilled/Semi-Skilled', 30: 'Skilled/Semi-Skilled', 31: 'Skilled/Semi-Skilled', \n",
    "    32: 'Skilled/Semi-Skilled', 33: 'Skilled/Semi-Skilled', 34: 'Skilled/Semi-Skilled', \n",
    "    36: 'Skilled/Semi-Skilled', 37: 'Skilled/Semi-Skilled', 38: 'Skilled/Semi-Skilled', \n",
    "    39: 'Skilled/Semi-Skilled', 40: 'Skilled/Semi-Skilled', 41: 'Skilled/Semi-Skilled', \n",
    "    42: 'Skilled/Semi-Skilled',\n",
    "\n",
    "    # Mapping for Unskilled Occupations\n",
    "    10: 'Unskilled', 12: 'Unskilled', 43: 'Unskilled', \n",
    "    44: 'Unskilled', 45: 'Unskilled', 46: 'Unskilled'\n",
    "}\n",
    "\n",
    "df_school['MotherOcc'] = df_school['MotherOcc'].map(occ_mapping)\n",
    "# Example of mapping\n",
    "df_school['FatherOcc'] = df_school['FatherOcc'].map(occ_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['Displaced'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 0 to 'No' and 1 to 'Yes'\n",
    "Displaced_mapping = {0: 'No', 1: 'Yes'}\n",
    "\n",
    "# Apply the mapping to the 'Scholarship' column\n",
    "df_school['Displaced'] = df_school['Displaced'].map(Displaced_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['EduNeeds'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 0 to 'No' and 1 to 'Yes'\n",
    "EduNeeds_mapping = {0: 'No', 1: 'Yes'}\n",
    "\n",
    "# Apply the mapping to the 'Scholarship' column\n",
    "df_school['EduNeeds'] = df_school['EduNeeds'].map(EduNeeds_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['Debtor'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 0 to 'No' and 1 to 'Yes'\n",
    "Debtor_mapping = {0: 'No', 1: 'Yes'}\n",
    "\n",
    "# Apply the mapping to the 'Scholarship' column\n",
    "df_school['Debtor'] = df_school['Debtor'].map(Debtor_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['FeesUpdated'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 0 to 'No' and 1 to 'Yes'\n",
    "FeesUpdated_mapping = {0: 'No', 1: 'Yes'}\n",
    "\n",
    "# Apply the mapping to the 'Scholarship' column\n",
    "df_school['FeesUpdated'] = df_school['FeesUpdated'].map(FeesUpdated_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school['International'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 0 to 'No' and 1 to 'Yes'\n",
    "International_mapping = {0: 'No', 1: 'Yes'}\n",
    "\n",
    "# Apply the mapping to the 'Scholarship' column\n",
    "df_school['International'] = df_school['International'].map(International_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ceck for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the initial number of rows\n",
    "initial_row_count = df_school.shape[0]\n",
    "\n",
    "# Remove duplicate rows from the DataFrame in place\n",
    "df_school.drop_duplicates(inplace=True)\n",
    "\n",
    "# Calculate the number of duplicated rows removed\n",
    "duplicates_removed = initial_row_count - df_school.shape[0]\n",
    "\n",
    "# Print the appropriate message based on the number of duplicates removed\n",
    "if duplicates_removed == 0:\n",
    "    print(\"There are no duplicated rows in the dataset.\")\n",
    "else:\n",
    "    print(f\"{duplicates_removed} duplicated rows were removed from the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numeric columns common to both 'test' and 'df_school' DataFrames\n",
    "numeric_columns = list(set(df_school.select_dtypes(include='number').columns))\n",
    "\n",
    "# Identify the categorical columns common to both 'test' and 'df_school' DataFrames\n",
    "categorical_columns = list(set(df_school.select_dtypes(exclude='number').columns))\n",
    "\n",
    "# Display the count and the list of numeric and categorical columns\n",
    "print(f\"There are {len(numeric_columns)} numeric columns: {numeric_columns}\")\n",
    "print(f\"There are {len(categorical_columns)} categorical columns: {categorical_columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_school[numeric_columns+categorical_columns]\n",
    "y = df_school['Target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split with a random_state, and add stratify for Classification\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y )\n",
    "\n",
    "X_train.shape, y_train.shape, X_eval.shape, y_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy=\"mean\").fit(X_train[numeric_columns])\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\").fit(X_train[categorical_columns])\n",
    "num_imputer.transform(X_train[numeric_columns])\n",
    "X_train_num_imputed = pd.DataFrame(num_imputer.transform(X_train[numeric_columns]), columns=numeric_columns)\n",
    "X_eval_num_imputed = pd.DataFrame(num_imputer.transform(X_eval[numeric_columns]), columns=numeric_columns)\n",
    "\n",
    "X_train_cat_imputed = pd.DataFrame(cat_imputer.transform(X_train[categorical_columns]), columns=categorical_columns)\n",
    "X_eval_cat_imputed = pd.DataFrame(cat_imputer.transform(X_eval[categorical_columns]), columns=categorical_columns)\n",
    "\n",
    "X_train_imputed = pd.concat([X_train_num_imputed, X_train_cat_imputed], axis=1)\n",
    "X_eval_imputed = pd.concat([X_eval_num_imputed, X_eval_cat_imputed], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the encoder instance with the specified parameters\n",
    "encoder = OneHotEncoder(sparse=False, drop=\"first\")\n",
    "\n",
    "# Fit the encoder on the training and evaluation categorical data combined\n",
    "encoder.fit(pd.concat([X_train_cat_imputed, X_eval_cat_imputed]))\n",
    "\n",
    "# Get the new column names after one-hot encoding\n",
    "cat_encoded_cols = encoder.get_feature_names_out().tolist()\n",
    "\n",
    "# Function to apply the encoder transformation and return a DataFrame\n",
    "def encode_categorical_data(encoder, data, columns):\n",
    "    return pd.DataFrame(encoder.transform(data), columns=columns, index=data.index)\n",
    "\n",
    "# Transform and encode categorical columns for training and evaluation sets\n",
    "X_train_cat_encoded = encode_categorical_data(encoder, X_train_cat_imputed, cat_encoded_cols)\n",
    "X_eval_cat_encoded = encode_categorical_data(encoder, X_eval_cat_imputed, cat_encoded_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler().fit(X_train_num_imputed)\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(scaler.transform(X_train_num_imputed), columns=numeric_columns)\n",
    "X_eval_num_scaled = pd.DataFrame(scaler.transform(X_eval_num_imputed), columns=numeric_columns)\n",
    "\n",
    "X_train_ready = pd.concat([X_train_num_scaled, X_train_cat_encoded], axis=1)\n",
    "X_eval_ready = pd.concat([X_eval_num_scaled, X_eval_cat_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ready.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_ready.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Machine Learning Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Train the Logistic Regression model using the training data\n",
    "log_reg.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict the target values for the evaluation set\n",
    "y_eval_pred = log_reg.predict(X_eval_ready)\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(classification_report(y_true=y_eval, y_pred=y_eval_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
